# Specify the namespaces to monitor here
namespacesToMonitor:
- loki
- mimir
- tempo
# The name of the cluster where this will be installed
clusterName: "meta-monitoring"
lokiNamespace: "loki"

# Set to true to write logs, metrics or traces to Grafana Cloud
cloud:
  logs:
    enabled: true
    endpoint: to_be_changed
    username: to_be_changed
    password: to_be_changed
  metrics:
    enabled: true
    endpoint: to_be_changed
    username: to_be_changed
    password: to_be_changed
  traces:
    enabled: true
    endpoint: to_be_changed
    username: to_be_changed
    password: to_be_changed

# Set to true for a local version of logs, metrics or traces
local:
  logs:
    enabled: false
  metrics:
    enabled: false
  traces:
    enabled: false
  minio:
    enabled: false  # This should be set to true if any of the previous is enabled

logs:
  # Adding regexes here will add a stage.replace block for logs. For more information see
  # https://grafana.com/docs/agent/latest/flow/reference/components/loki.process/#stagereplace-block
  piiRegexes:
  # This example replaces the word after password with *****
  # - expression: "password (\\\\S+)"
  #   source: ""         # Empty uses the log message
  #   replace: "*****""

  # The lines matching these will be kept in Loki
  retain:
  # This shows the queries
  - caller=metrics.go
  # This shows any errors
  - level=error
  # This shows the ingest requests and is very noisy. Uncomment to include.
  # - caller=push.go

# Set enabled = true to add the default logs/metrics/traces dashboards to the local Grafana
dashboards:
  logs:
    enabled: true
  metrics:
    enabled: true
  traces:
    enabled: true

global:
  minio:
    rootUser: "rootuser"
    rootPassword: "rootpassword"

kubeStateMetrics:
  # Scrape https://github.com/kubernetes/kube-state-metrics by default
  enabled: true
  # This endpoint is created when the helm chart from
  # https://artifacthub.io/packages/helm/prometheus-community/kube-state-metrics/
  # is used. Change this if kube-state-metrics is installed somewhere else.
  endpoint: kube-state-metrics.kube-state-metrics.svc.cluster.local:8080

# The following are configuration for the dependencies.
# These should usually not be changed.

loki:
  loki:
    auth_enabled: false
    storage:
      type: "s3"
      s3:
        insecure: true
        s3ForcePathStyle: true
      bucketNames:
        chunks: loki-chunks
        ruler: loki-ruler
    structuredConfig:
      common:
        storage:
          s3:
            access_key_id: "{{ .Values.global.minio.rootUser }}"
            endpoint: "{{ .Release.Name }}-minio.{{ .Release.Namespace }}.svc:9000"
            secret_access_key: "{{ .Values.global.minio.rootPassword }}"
      compactor:
        retention_enabled: true
      limits_config:
        retention_period: 30d
  monitoring:
    dashboards:
      enabled: false
    rules:
      enabled: false
    serviceMonitor:
      enabled: false
    selfMonitoring:
      enabled: false
      grafanaAgent:
        installOperator: false
    lokiCanary:
      enabled: false
  test:
    enabled: false

grafana-agent:
  agent:
    clustering:
      enabled: true
    configMap:
      create: false
      name: "agent-configmap"
      key: 'config.river'
    resources:
      requests:
        cpu: '1000m'
        memory: '600Mi'
      limits:
        memory: '4Gi'
  controller:
    type: "statefulset"
    autoscaling:
      enabled: true
      minReplicas: 3
      maxReplicas: 30
      targetMemoryUtilizationPercentage: 90
      targetCPUUtilizationPercentage: 90

mimir-distributed:
  minio:
    enabled: false
  mimir:
    structuredConfig:
      alertmanager_storage:
        s3:
          bucket_name: mimir-ruler
          access_key_id: "{{ .Values.global.minio.rootUser }}"
          endpoint: "{{ .Release.Name }}-minio.{{ .Release.Namespace }}.svc:9000"
          secret_access_key: "{{ .Values.global.minio.rootPassword }}"
          insecure: true
      blocks_storage:
        backend: s3
        s3:
          bucket_name: mimir-tsdb
          access_key_id: "{{ .Values.global.minio.rootUser }}"
          endpoint: "{{ .Release.Name }}-minio.{{ .Release.Namespace }}.svc:9000"
          secret_access_key: "{{ .Values.global.minio.rootPassword }}"
          insecure: true
      ruler_storage:
        s3:
          bucket_name: mimir-ruler
          access_key_id: "{{ .Values.global.minio.rootUser }}"
          endpoint: "{{ .Release.Name }}-minio.{{ .Release.Namespace }}.svc:9000"
          secret_access_key: "{{ .Values.global.minio.rootPassword }}"
          insecure: true
      limits:
        compactor_blocks_retention_period: 30d

tempo-distributed:
  tempo:
    structuredConfig:
      storage:
        trace:
          backend: s3
          s3:
            bucket: tempo
            endpoint: "{{ .Release.Name }}-minio.{{ .Release.Namespace }}.svc:9000"
            access_key: "{{ .Values.global.minio.rootUser }}"
            secret_key: "{{ .Values.global.minio.rootPassword }}"
            insecure: true
      compactor:
        compaction:
          block_retention: 30d
  traces:
    otlp:
      http:
        enabled: true
      grpc:
        enabled: true

minio:
  rootUser: rootuser
  rootPassword: rootpassword
  buckets:
    - name: loki-chunks
      policy: none
      purge: false
    - name: loki-ruler
      policy: none
      purge: false
    - name: tempo
      policy: none
      purge: false
    - name: mimir-ruler
      policy: none
      purge: false
    - name: mimir-tsdb
      policy: none
      purge: false
  mode: standalone
  persistence:
    size: 5Gi
  resources:
    requests:
      cpu: 100m
      memory: 128Mi
  # Changed the mc config path to '/tmp' from '/etc' as '/etc' is only writable by root and OpenShift will not permit this.
  configPathmc: "/tmp/minio/mc/"
